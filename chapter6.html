<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>How LLMs Generate Text - LLM Learning Guide</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js">
        // Mobile menu toggle
        function toggleMobileMenu() {
            const nav = document.getElementById('nav-sidebar');
            nav.classList.toggle('open');
        }

        // Close mobile menu when clicking outside
        document.addEventListener('click', function(event) {
            const nav = document.getElementById('nav-sidebar');
            const toggle = document.querySelector('.mobile-menu-toggle');
            
            if (nav && toggle && 
                !nav.contains(event.target) && 
                !toggle.contains(event.target) &&
                nav.classList.contains('open')) {
                nav.classList.remove('open');
            }
        });

        // Close mobile menu when clicking a link
        document.querySelectorAll('.nav-sidebar a').forEach(link => {
            link.addEventListener('click', function() {
                const nav = document.getElementById('nav-sidebar');
                if (nav && window.innerWidth <= 768) {
                    nav.classList.remove('open');
                }
            });
        });
</script>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <!-- Mobile Menu Toggle -->
        <button class="mobile-menu-toggle" onclick="toggleMobileMenu()" aria-label="Toggle menu">â˜°</button>
        <header class="header">
            <h1>âœ¨ How LLMs Generate Text</h1>
            <p class="subtitle">Chapter 6 of 11</p>
        </header>

        
    <nav class="nav-sidebar" id="nav-sidebar">
        <ul>
            <li><a href="index.html">ğŸ  Home</a></li>
            <li><a href="chapter1.html">ğŸ“– Chapter 1: Introduction to LLMs</a></li>
            <li><a href="chapter2.html">âš™ï¸ Chapter 2: Transformer Architecture</a></li>
            <li><a href="chapter3.html">ğŸ”¢ Chapter 3: Tokenization</a></li>
            <li><a href="chapter4.html">ğŸ‘ï¸ Chapter 4: Attention Mechanism</a></li>
            <li><a href="chapter5.html">ğŸ“ Chapter 5: Training LLMs</a></li>
            <li><a href="chapter6.html">âœ¨ Chapter 6: Text Generation</a></li>
            <li><a href="chapter7.html">âœ… Chapter 7: Why LLMs Succeed</a></li>
            <li><a href="chapter8.html">âŒ Chapter 8: Why LLMs Fail</a></li>
            <li><a href="chapter9.html">ğŸ’¬ Chapter 9: NL2SQL Overview</a></li>
            <li><a href="chapter10.html">ğŸ—ï¸ Chapter 10: Your NL2SQL System</a></li>
            <li><a href="chapter11.html">ğŸ“š Chapter 11: Examples & Case Studies</a></li>
        </ul>
    </nav>

        <main class="main-content">
            <div class="chapter-header">
                <h1>âœ¨ How LLMs Generate Text</h1>
                <p>Chapter 6 of 11 - Complete Learning Guide</p>
            </div>

            <div class="chapter-nav"><a href="chapter5.html">â† Previous Chapter</a><a href="index.html">ğŸ  Home</a><a href="chapter7.html">Next Chapter â†’</a></div>

            <div class="section">
                <h3>The Generation Process</h3>
<p><div class="diagram-container"><div class="mermaid">
sequenceDiagram
    participant User
    participant Tokenizer
    participant LLM
    participant Decoder
    participant User

    User->>Tokenizer: "Show me students"
    Tokenizer->>LLM: [1234, 567, 890]
    LLM->>LLM: Process through layers
    LLM->>Decoder: Probability distribution
    Decoder->>LLM: Sample next token
    LLM->>Tokenizer: [12345]
    Tokenizer->>User: "enrolled"
    Note over LLM: Repeat until complete
</div></div></p>
<h3>Step-by-Step Generation</h3>
<h4>Step 1: Input Processing</h4>
<pre><code>User: "Show me students"
<p>â†“ Tokenization</p>
<p>Tokens: [1234, 567, 890]</p>
<p>â†“ Embedding</p>
<p>Vectors: [[0.1, 0.2, ...], [0.3, 0.1, ...], ...]</p>
<p>â†“ Transformer Layers (96 layers in GPT-3)</p>
<p>Refined understanding at each layer</p>
<p></code></pre></p>
<h4>Step 2: Next Token Prediction</h4>
<p>After processing input, the model outputs a <strong>probability distribution</strong> over all possible tokens:</p>
<pre><code>Token          Probability
<p>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</p>
<p>"enrolled"     0.35  â† Most likely</p>
<p>"in"           0.25</p>
<p>"with"         0.15</p>
<p>"from"         0.10</p>
<p>"for"          0.08</p>
<p>...            ...</p>
<p></code></pre></p>
<h4>Step 3: Sampling Strategy</h4>
<p><strong>Greedy Decoding</strong> (always pick highest probability):</p>
<pre><code>Always pick: "enrolled" (0.35)
<p></code></pre></p>
<p><strong>Temperature Sampling</strong> (adds randomness):</p>
<pre><code>temperature = 0.7  # Lower = more deterministic
<p># Higher temperature = more creative/random</p>
<p></code></pre></p>
<p><strong>Top-k Sampling</strong> (consider only top k options):</p>
<pre><code>top_k = 50  # Only consider top 50 most likely tokens
<p></code></pre></p>
<p><strong>Top-p (Nucleus) Sampling</strong> (consider tokens until cumulative probability reaches p):</p>
<pre><code>top_p = 0.9  # Consider tokens until 90% probability mass
<p></code></pre></p>
<h4>Step 4: Iterative Generation</h4>
<pre><code>Input: "Show me students"
<p>â†“</p>
<p>Generate: "enrolled"</p>
<p>â†“</p>
<p>Input: "Show me students enrolled"</p>
<p>â†“</p>
<p>Generate: "in"</p>
<p>â†“</p>
<p>Input: "Show me students enrolled in"</p>
<p>â†“</p>
<p>Generate: "2024"</p>
<p>â†“</p>
<p>Complete: "Show me students enrolled in 2024"</p>
<p></code></pre></p>
<h3>Why This Works</h3>
<p>The model has seen millions of similar patterns:</p>
<ul>
<li>"Show me X enrolled in Y"</li>
<li>"List students in year Z"</li>
<li>"Get all X from Y"</li>
</ul>
<p>It learns these patterns and applies them!</p>
<h3>Generation in Your NL2SQL System</h3>
<pre><code># Simplified version of what happens
<p>question = "Show me all students enrolled in 2024"</p>
<p># 1. Intent Classification</p>
<p>intent = determine_intent(question)  # Returns: "sql"</p>
<p># 2. Hybrid Search (find relevant tables)</p>
<p>tables, metadata = hybrid_search(question)</p>
<p># 3. LLM generates SQL</p>
<p>prompt = f"""</p>
<p>System: {SQL_PREFIX}</p>
<p>User: {question}</p>
<p>Context: {metadata}</p>
<p>"""</p>
<p>sql_query = llm.generate(prompt)</p>
<p># Result: "SELECT * FROM students WHERE enrollment_year = 2024"</p>
<p></code></pre></p>
<p>---</p>
            </div>

            <div class="chapter-nav"><a href="chapter5.html">â† Previous Chapter</a><a href="index.html">ğŸ  Home</a><a href="chapter7.html">Next Chapter â†’</a></div>
        </main>

        <footer class="footer">
            <p>Â© 2024 NL2SQL Project - Complete LLM Learning Guide</p>
            <p>Chapter 6 of 11</p>
        </footer>
    </div>

    <script>
        mermaid.initialize({ 
            startOnLoad: true,
            theme: 'default',
            flowchart: { useMaxWidth: true, htmlLabels: true }
        });
    </script>
</body>
</html>