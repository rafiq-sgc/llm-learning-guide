<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>How LLMs Work: The Transformer Architecture - LLM Learning Guide</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js">
        // Mobile menu toggle
        function toggleMobileMenu() {
            const nav = document.getElementById('nav-sidebar');
            nav.classList.toggle('open');
        }

        // Close mobile menu when clicking outside
        document.addEventListener('click', function(event) {
            const nav = document.getElementById('nav-sidebar');
            const toggle = document.querySelector('.mobile-menu-toggle');
            
            if (nav && toggle && 
                !nav.contains(event.target) && 
                !toggle.contains(event.target) &&
                nav.classList.contains('open')) {
                nav.classList.remove('open');
            }
        });

        // Close mobile menu when clicking a link
        document.querySelectorAll('.nav-sidebar a').forEach(link => {
            link.addEventListener('click', function() {
                const nav = document.getElementById('nav-sidebar');
                if (nav && window.innerWidth <= 768) {
                    nav.classList.remove('open');
                }
            });
        });
</script>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div class="container">
        <!-- Mobile Menu Toggle -->
        <button class="mobile-menu-toggle" onclick="toggleMobileMenu()" aria-label="Toggle menu">â˜°</button>
        <header class="header">
            <h1>âš™ï¸ How LLMs Work: The Transformer Architecture</h1>
            <p class="subtitle">Chapter 2 of 11</p>
        </header>

        
    <nav class="nav-sidebar" id="nav-sidebar">
        <ul>
            <li><a href="index.html">ğŸ  Home</a></li>
            <li><a href="chapter1.html">ğŸ“– Chapter 1: Introduction to LLMs</a></li>
            <li><a href="chapter2.html">âš™ï¸ Chapter 2: Transformer Architecture</a></li>
            <li><a href="chapter3.html">ğŸ”¢ Chapter 3: Tokenization</a></li>
            <li><a href="chapter4.html">ğŸ‘ï¸ Chapter 4: Attention Mechanism</a></li>
            <li><a href="chapter5.html">ğŸ“ Chapter 5: Training LLMs</a></li>
            <li><a href="chapter6.html">âœ¨ Chapter 6: Text Generation</a></li>
            <li><a href="chapter7.html">âœ… Chapter 7: Why LLMs Succeed</a></li>
            <li><a href="chapter8.html">âŒ Chapter 8: Why LLMs Fail</a></li>
            <li><a href="chapter9.html">ğŸ’¬ Chapter 9: NL2SQL Overview</a></li>
            <li><a href="chapter10.html">ğŸ—ï¸ Chapter 10: Your NL2SQL System</a></li>
            <li><a href="chapter11.html">ğŸ“š Chapter 11: Examples & Case Studies</a></li>
        </ul>
    </nav>

        <main class="main-content">
            <div class="chapter-header">
                <h1>âš™ï¸ How LLMs Work: The Transformer Architecture</h1>
                <p>Chapter 2 of 11 - Complete Learning Guide</p>
            </div>

            <div class="chapter-nav"><a href="chapter1.html">â† Previous Chapter</a><a href="index.html">ğŸ  Home</a><a href="chapter3.html">Next Chapter â†’</a></div>

            <div class="section">
                <h3>The Transformer: Foundation of Modern LLMs</h3>
<p>The <strong>Transformer</strong> architecture, introduced in 2017 by Google's "Attention Is All You Need" paper, revolutionized NLP. It's the architecture behind GPT, BERT, and most modern LLMs.</p>
<h3>Core Components</h3>
<p><div class="diagram-container"><div class="mermaid">
graph TD
    A[Input Text] --> B[Tokenization]
    B --> C[Embedding Layer]
    C --> D[Positional Encoding]
    D --> E[Multi-Head Attention]
    E --> F[Feed Forward Network]
    F --> G[Layer Normalization]
    G --> H{More Layers?}
    H -->|Yes| E
    H -->|No| I[Output Layer]
    I --> J[Generated Text]
</div></div></p>
<h3>1. <strong>Embedding Layer</strong></h3>
<ul>
<li>Converts tokens (words/subwords) into dense vectors (numbers)</li>
<li>Each token becomes a point in high-dimensional space</li>
<li>Similar words are closer together in this space</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code>"cat" â†’ [0.2, -0.5, 0.8, ..., 0.1]  (vector of 768 or more dimensions)
<p>"dog" â†’ [0.3, -0.4, 0.7, ..., 0.2]  (similar vector, close to "cat")</p>
<p>"airplane" â†’ [-0.1, 0.9, -0.3, ..., -0.5]  (very different vector)</p>
<p></code></pre></p>
<h3>2. <strong>Positional Encoding</strong></h3>
<ul>
<li>Adds information about word position in the sentence</li>
<li>Transformers don't inherently understand order, so we add position info</li>
</ul>
<p><strong>Why it matters:</strong></p>
<pre><code>"The cat sat on the mat" â‰  "The mat sat on the cat"
<p>Position matters!</p>
<p></code></pre></p>
<h3>3. <strong>Multi-Head Attention</strong> (Most Important!)</h3>
<ul>
<li>Allows the model to focus on different parts of the input simultaneously</li>
<li>Each "head" looks at different relationships</li>
<li>We'll dive deeper into this in Section 4</li>
</ul>
<h3>4. <strong>Feed Forward Network</strong></h3>
<ul>
<li>Two-layer neural network that processes each position independently</li>
<li>Adds non-linearity and complexity to the model</li>
</ul>
<h3>5. <strong>Layer Normalization</strong></h3>
<ul>
<li>Stabilizes training and improves performance</li>
<li>Normalizes the values to prevent them from growing too large</li>
</ul>
<h3>Architecture Stack</h3>
<p><div class="diagram-container"><div class="mermaid">
graph LR
    A[Input] --> B[Layer 1]
    B --> C[Layer 2]
    C --> D[Layer 3]
    D --> E[...]
    E --> F[Layer N]
    F --> G[Output]
    
    style B fill:#e1f5ff
    style C fill:#e1f5ff
    style D fill:#e1f5ff
    style F fill:#e1f5ff
</div></div></p>
<p><strong>GPT-3 has 96 layers!</strong> Each layer refines the understanding.</p>
<p>---</p>
            </div>

            <div class="chapter-nav"><a href="chapter1.html">â† Previous Chapter</a><a href="index.html">ğŸ  Home</a><a href="chapter3.html">Next Chapter â†’</a></div>
        </main>

        <footer class="footer">
            <p>Â© 2024 NL2SQL Project - Complete LLM Learning Guide</p>
            <p>Chapter 2 of 11</p>
        </footer>
    </div>

    <script>
        mermaid.initialize({ 
            startOnLoad: true,
            theme: 'default',
            flowchart: { useMaxWidth: true, htmlLabels: true }
        });
    </script>
</body>
</html>